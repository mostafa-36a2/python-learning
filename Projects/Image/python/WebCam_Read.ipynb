{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd34291-8f09-49ba-b723-2d712780f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=Y7XBsFzByTQ\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import numpy\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcf459f8-6131-4c20-91b8-d2d90f15f413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing Face Please Be in sufficient Lights...\n",
      "analysing dirs ['man2', 'a man', 'man3', 'musk', 'mostafa'] opening man2\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/man2/3.jpg  in subdir  man2  with label:  0\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/man2/1.jpg  in subdir  man2  with label:  0\n",
      "analysing dirs ['man2', 'a man', 'man3', 'musk', 'mostafa'] opening a man\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/a man/2.jpeg  in subdir  a man  with label:  1\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/a man/1.jpeg  in subdir  a man  with label:  1\n",
      "analysing dirs ['man2', 'a man', 'man3', 'musk', 'mostafa'] opening man3\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/man3/1.jpg  in subdir  man3  with label:  2\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/man3/2.jpg  in subdir  man3  with label:  2\n",
      "analysing dirs ['man2', 'a man', 'man3', 'musk', 'mostafa'] opening musk\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/musk/2.jpeg  in subdir  musk  with label:  3\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/musk/3.png  in subdir  musk  with label:  3\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/musk/1.jpeg  in subdir  musk  with label:  3\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/musk/4.jpeg  in subdir  musk  with label:  3\n",
      "analysing dirs ['man2', 'a man', 'man3', 'musk', 'mostafa'] opening mostafa\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/mostafa/5.jpg  in subdir  mostafa  with label:  4\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/mostafa/3.jpg  in subdir  mostafa  with label:  4\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/mostafa/1.jpg  in subdir  mostafa  with label:  4\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/mostafa/4.jpg  in subdir  mostafa  with label:  4\n",
      "reading from path: /home/mostafa/Desktop/OCR/face/datasets/mostafa/2.jpg  in subdir  mostafa  with label:  4\n"
     ]
    }
   ],
   "source": [
    "datasets = '/home/mostafa/Desktop/OCR/face/datasets'\n",
    " \n",
    "# Part 1: Create fisherRecognizer\n",
    "print('Recognizing Face Please Be in sufficient Lights...')\n",
    " \n",
    "# Create a list of images and a list of corresponding names\n",
    "(images, labels, names, id) = ([], [], {}, 0)\n",
    "for (subdirs, dirs, files) in os.walk(datasets):\n",
    "    for subdir in dirs:\n",
    "        print('analysing dirs',dirs,'opening',subdir)\n",
    "        names[id] = subdir #the name comes from the subdir\n",
    "        subjectpath = os.path.join(datasets, subdir)\n",
    "        for filename in os.listdir(subjectpath):\n",
    "            path = subjectpath + '/' + filename\n",
    "            images.append(cv2.imread(path, 0)) #the image comes from the path\n",
    "            labels.append(int(id)) #label is the id\n",
    "            print('reading from path:',path,' in subdir ',subdir,' with label: ',id)\n",
    "        id += 1\n",
    "(width, height) = (130, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b1ea581-039b-4908-9f17-4e35483aa685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Numpy array from the two lists above\n",
    "(images, labels) = [numpy.array(lis) for lis in [images, labels]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9215a95b-139b-4aac-902d-eabb50e5d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV trains a model from the images\n",
    "# NOTE FOR OpenCV2: remove '.face'\n",
    "model = cv2.face.LBPHFaceRecognizer_create() \n",
    "\n",
    "model.train(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be140427-c04e-43d6-a378-3a981224dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier('/home/mostafa/Desktop/OCR/face/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01096cd9-28c4-44be-b1c6-e2b52f8971b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoCapture 0 successfully done\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(-1)\n",
    "if not cap.isOpened():\n",
    "    print('VideoCapture -1 failed')\n",
    "    cap=cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('VideoCapture 0 failed')\n",
    "    cap=cv2.VideoCapture(1)\n",
    "else:\n",
    "    print('VideoCapture 0 successfully done')\n",
    "    \n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot Open Video\")\n",
    "    \n",
    "while True:\n",
    "    # Read the input image\n",
    "    ret,frame = cap.read()\n",
    "    # Convert into grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    Report='found '+str(len(faces))+' faces'\n",
    "    # Draw rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Try to recognize the face\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        face_resize = cv2.resize(face, (width, height))\n",
    "        (id,prediction) = model.predict(face_resize)\n",
    "        \n",
    "        if prediction<500:\n",
    "            cv2.putText(frame, '% s - %.0f' %(names[id], prediction), (x-10, y-10),cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
    "            Report=Report+\", detecting \"+names[id]\n",
    "        else:\n",
    "            cv2.putText(frame, 'not recognized',(x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0))\n",
    "\n",
    "    cv2.putText(frame, 'Report: '+Report,(10, 18), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0))\n",
    "    cv2.imshow('img', frame)\n",
    "    \n",
    "    # Display the output\n",
    "    #cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c917451-abf1-4f53-8f4b-d4536ca98a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "while False:\n",
    "    ret,frame = cap.read()\n",
    "    cntr=cntr+1\n",
    "    if (cntr%10)==0:\n",
    "        imgH,imgW,_=frame.shape\n",
    "        x1,y1,w1,h1=0,0,imgH,imgW\n",
    "        imgChar=pytesseract.image_to_string(frame)\n",
    "        imgBoxes=pytesseract.image_to_boxes(frame)\n",
    "        \n",
    "        for boxes in imgBoxes.splitlines():\n",
    "            boxes=boxes.split(' ')\n",
    "            x,y,w,h=int(boxes[1]),int(boxes[2]),int(boxes[3]),int(boxes[4])\n",
    "            cv2.rectangle(frame,(x,imgH-y),(w,imgH-h),(0,0,255),1)\n",
    "            \n",
    "        cv2.putText(frame,imgChar, (x1+int(w1/50),y1+int(h1/50)),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,0,0),2)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.imshow('Text detaction',frame)\n",
    "    if cv2.waitKey():\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
